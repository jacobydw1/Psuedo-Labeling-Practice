{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instant Gratification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Competition Link >>> https://www.kaggle.com/c/instant-gratification/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This notebook is a kaggle competition that introduces the process of Psuedo Labeling\n",
    "to improve predictions on data. Pseudo labeling is the process of adding confident predicted\n",
    "test data to your training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Description:\n",
    "    \n",
    "This is an anonymized, binary classification dataset found on a USB stick that washed ashore in a bottle. There was no data dictionary with the dataset, but this poem was handwritten on an accompanying scrap of paper:\n",
    "\n",
    ">Silly column names abound, \n",
    "but the test set is a mystery. \n",
    ">Careful how you pick and slice, \n",
    ">or be left behind by history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data \n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>muggy-smalt-axolotl-pembus</th>\n",
       "      <th>dorky-peach-sheepdog-ordinal</th>\n",
       "      <th>slimy-seashell-cassowary-goose</th>\n",
       "      <th>snazzy-harlequin-chicken-distraction</th>\n",
       "      <th>frumpy-smalt-mau-ordinal</th>\n",
       "      <th>stealthy-beige-pinscher-golden</th>\n",
       "      <th>chummy-cream-tarantula-entropy</th>\n",
       "      <th>hazy-emerald-cuttlefish-unsorted</th>\n",
       "      <th>nerdy-indigo-wolfhound-sorted</th>\n",
       "      <th>...</th>\n",
       "      <th>wheezy-myrtle-mandrill-entropy</th>\n",
       "      <th>wiggy-lilac-lemming-sorted</th>\n",
       "      <th>gloppy-cerise-snail-contributor</th>\n",
       "      <th>woozy-silver-havanese-gaussian</th>\n",
       "      <th>jumpy-thistle-discus-sorted</th>\n",
       "      <th>muggy-turquoise-donkey-important</th>\n",
       "      <th>blurry-buff-hyena-entropy</th>\n",
       "      <th>bluesy-chocolate-kudu-fepid</th>\n",
       "      <th>gamy-white-monster-expert</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>707b395ecdcbb4dc2eabea00e4d1b179</td>\n",
       "      <td>-2.070654</td>\n",
       "      <td>1.018160</td>\n",
       "      <td>0.228643</td>\n",
       "      <td>0.857221</td>\n",
       "      <td>0.052271</td>\n",
       "      <td>0.230303</td>\n",
       "      <td>-6.385090</td>\n",
       "      <td>0.439369</td>\n",
       "      <td>-0.721946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351895</td>\n",
       "      <td>0.618824</td>\n",
       "      <td>-1.542423</td>\n",
       "      <td>0.598175</td>\n",
       "      <td>0.611757</td>\n",
       "      <td>0.678772</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>-0.806677</td>\n",
       "      <td>-0.193649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5880c03c6582a7b42248668e56b4bdec</td>\n",
       "      <td>-0.491702</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>1.071266</td>\n",
       "      <td>-0.346347</td>\n",
       "      <td>-0.082209</td>\n",
       "      <td>0.110579</td>\n",
       "      <td>-0.382374</td>\n",
       "      <td>-0.229620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.645115</td>\n",
       "      <td>-1.246090</td>\n",
       "      <td>2.613357</td>\n",
       "      <td>-0.479664</td>\n",
       "      <td>1.581289</td>\n",
       "      <td>0.931258</td>\n",
       "      <td>0.151937</td>\n",
       "      <td>-0.766595</td>\n",
       "      <td>0.474351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4ccbcb3d13e5072ff1d9c61afe2c4f77</td>\n",
       "      <td>-1.680473</td>\n",
       "      <td>0.860529</td>\n",
       "      <td>-1.076195</td>\n",
       "      <td>0.740124</td>\n",
       "      <td>3.678445</td>\n",
       "      <td>0.288558</td>\n",
       "      <td>0.515875</td>\n",
       "      <td>0.920590</td>\n",
       "      <td>-1.223277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516422</td>\n",
       "      <td>0.130521</td>\n",
       "      <td>-0.459210</td>\n",
       "      <td>2.028205</td>\n",
       "      <td>-0.093968</td>\n",
       "      <td>-0.218274</td>\n",
       "      <td>-0.163136</td>\n",
       "      <td>-0.870289</td>\n",
       "      <td>0.064038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e350f17a357f12a1941f0837afb7eb8d</td>\n",
       "      <td>0.183774</td>\n",
       "      <td>0.919134</td>\n",
       "      <td>-0.946958</td>\n",
       "      <td>0.918492</td>\n",
       "      <td>0.862278</td>\n",
       "      <td>1.155287</td>\n",
       "      <td>0.911106</td>\n",
       "      <td>0.562598</td>\n",
       "      <td>-1.349685</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.168967</td>\n",
       "      <td>1.385089</td>\n",
       "      <td>-0.353028</td>\n",
       "      <td>3.316150</td>\n",
       "      <td>-0.524087</td>\n",
       "      <td>-0.794327</td>\n",
       "      <td>3.936365</td>\n",
       "      <td>0.682989</td>\n",
       "      <td>-2.521211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a8f910ea6075b6376af079055965ff68</td>\n",
       "      <td>-0.203933</td>\n",
       "      <td>-0.177252</td>\n",
       "      <td>0.368074</td>\n",
       "      <td>-0.701320</td>\n",
       "      <td>-1.104391</td>\n",
       "      <td>0.735760</td>\n",
       "      <td>0.894273</td>\n",
       "      <td>-1.375826</td>\n",
       "      <td>-5.144946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.279168</td>\n",
       "      <td>1.544356</td>\n",
       "      <td>2.959727</td>\n",
       "      <td>1.641201</td>\n",
       "      <td>-0.130818</td>\n",
       "      <td>-0.264292</td>\n",
       "      <td>-0.748668</td>\n",
       "      <td>0.964218</td>\n",
       "      <td>0.087079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  muggy-smalt-axolotl-pembus  \\\n",
       "0  707b395ecdcbb4dc2eabea00e4d1b179                   -2.070654   \n",
       "1  5880c03c6582a7b42248668e56b4bdec                   -0.491702   \n",
       "2  4ccbcb3d13e5072ff1d9c61afe2c4f77                   -1.680473   \n",
       "3  e350f17a357f12a1941f0837afb7eb8d                    0.183774   \n",
       "4  a8f910ea6075b6376af079055965ff68                   -0.203933   \n",
       "\n",
       "   dorky-peach-sheepdog-ordinal  slimy-seashell-cassowary-goose  \\\n",
       "0                      1.018160                        0.228643   \n",
       "1                      0.082645                       -0.011193   \n",
       "2                      0.860529                       -1.076195   \n",
       "3                      0.919134                       -0.946958   \n",
       "4                     -0.177252                        0.368074   \n",
       "\n",
       "   snazzy-harlequin-chicken-distraction  frumpy-smalt-mau-ordinal  \\\n",
       "0                              0.857221                  0.052271   \n",
       "1                              1.071266                 -0.346347   \n",
       "2                              0.740124                  3.678445   \n",
       "3                              0.918492                  0.862278   \n",
       "4                             -0.701320                 -1.104391   \n",
       "\n",
       "   stealthy-beige-pinscher-golden  chummy-cream-tarantula-entropy  \\\n",
       "0                        0.230303                       -6.385090   \n",
       "1                       -0.082209                        0.110579   \n",
       "2                        0.288558                        0.515875   \n",
       "3                        1.155287                        0.911106   \n",
       "4                        0.735760                        0.894273   \n",
       "\n",
       "   hazy-emerald-cuttlefish-unsorted  nerdy-indigo-wolfhound-sorted  ...  \\\n",
       "0                          0.439369                      -0.721946  ...   \n",
       "1                         -0.382374                      -0.229620  ...   \n",
       "2                          0.920590                      -1.223277  ...   \n",
       "3                          0.562598                      -1.349685  ...   \n",
       "4                         -1.375826                      -5.144946  ...   \n",
       "\n",
       "   wheezy-myrtle-mandrill-entropy  wiggy-lilac-lemming-sorted  \\\n",
       "0                        0.351895                    0.618824   \n",
       "1                       -0.645115                   -1.246090   \n",
       "2                        0.516422                    0.130521   \n",
       "3                       -1.168967                    1.385089   \n",
       "4                       -0.279168                    1.544356   \n",
       "\n",
       "   gloppy-cerise-snail-contributor  woozy-silver-havanese-gaussian  \\\n",
       "0                        -1.542423                        0.598175   \n",
       "1                         2.613357                       -0.479664   \n",
       "2                        -0.459210                        2.028205   \n",
       "3                        -0.353028                        3.316150   \n",
       "4                         2.959727                        1.641201   \n",
       "\n",
       "   jumpy-thistle-discus-sorted  muggy-turquoise-donkey-important  \\\n",
       "0                     0.611757                          0.678772   \n",
       "1                     1.581289                          0.931258   \n",
       "2                    -0.093968                         -0.218274   \n",
       "3                    -0.524087                         -0.794327   \n",
       "4                    -0.130818                         -0.264292   \n",
       "\n",
       "   blurry-buff-hyena-entropy  bluesy-chocolate-kudu-fepid  \\\n",
       "0                   0.247059                    -0.806677   \n",
       "1                   0.151937                    -0.766595   \n",
       "2                  -0.163136                    -0.870289   \n",
       "3                   3.936365                     0.682989   \n",
       "4                  -0.748668                     0.964218   \n",
       "\n",
       "   gamy-white-monster-expert  target  \n",
       "0                  -0.193649       0  \n",
       "1                   0.474351       0  \n",
       "2                   0.064038       1  \n",
       "3                  -2.521211       0  \n",
       "4                   0.087079       0  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 262144 entries, 0 to 262143\n",
      "Columns: 258 entries, id to target\n",
      "dtypes: float64(255), int64(2), object(1)\n",
      "memory usage: 516.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 & 2 : Build First QDA Model and Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA scores CV = 0.63184\n"
     ]
    }
   ],
   "source": [
    "cols = [c for c in train.columns if c not in ['id', 'target']]\n",
    "        \n",
    "cols.remove('wheezy-copper-turtle-magic')\n",
    "oof = np.zeros(len(train))\n",
    "preds = np.zeros(len(test))\n",
    "\n",
    "# Build 512 Seperate Models\n",
    "num = test['wheezy-copper-turtle-magic'] < 512\n",
    "test2 = test[num]\n",
    "\n",
    "num2 = train['wheezy-copper-turtle-magic'] < 512\n",
    "train2 = train[num2]\n",
    "   \n",
    "    \n",
    "    \n",
    "idx1 = train2.index; idx2 = test2.index\n",
    "train2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "# FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "sel = VarianceThreshold(threshold=1.2).fit(train2[cols])\n",
    "train3 = sel.transform(train2[cols])\n",
    "test3 = sel.transform(test2[cols])\n",
    "    \n",
    "    \n",
    "# STRATIFIED K-FOLD\n",
    "skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "for train_index, test_index in skf.split(train3, train2['target']):\n",
    "        \n",
    "    #MODEL AND PREDICT WITH QDA\n",
    "    clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n",
    "    clf.fit(train3[train_index,:], train2.loc[train_index]['target'])\n",
    "    oof[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "    preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "       \n",
    "    #if i%64==0: print(i)\n",
    "\n",
    "# PRINT CV AUC\n",
    "auc = roc_auc_score(train['target'],oof)\n",
    "print('QDA scores CV =',round(auc,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((262144, 258), (262144, 255))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo Labeled QDA scores CV = 0.63403\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE VARIABLES\n",
    "test['target'] = preds\n",
    "oof = np.zeros(len(train))\n",
    "preds = np.zeros(len(test))\n",
    "\n",
    "# Build 512 Seperate Models\n",
    "num3 = test['wheezy-copper-turtle-magic'] < 512\n",
    "test2 = test[num3]\n",
    "\n",
    "num4 = train['wheezy-copper-turtle-magic'] < 512\n",
    "train2 = train[num4]\n",
    "\n",
    " \n",
    "train2p = train2.copy(); idx1 = train2.index \n",
    "\n",
    "    \n",
    "# ADD PSEUDO LABELED DATA\n",
    "test2p = test2[ (test2['target']<=0.01) | (test2['target']>=0.99) ].copy()\n",
    "test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n",
    "test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n",
    "train2p = pd.concat([train2p,test2p],axis=0)\n",
    "train2p.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "#FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "sel = VarianceThreshold(threshold=1.15).fit(train2p[cols])     \n",
    "train3p = sel.transform(train2p[cols])\n",
    "train3 = sel.transform(train2[cols])\n",
    "test3 = sel.transform(test2[cols])\n",
    "        \n",
    "# STRATIFIED K FOLD\n",
    "skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "for train_index, test_index in skf.split(train3p, train2p['target']):\n",
    "    test_index3 = test_index[ test_index<len(train3) ] # ignore pseudo in oof\n",
    "        \n",
    "    # MODEL AND PREDICT WITH QDA\n",
    "    clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n",
    "    clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n",
    "    oof[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n",
    "    preds[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "       \n",
    "    #if k%64==0: print(k)\n",
    "        \n",
    "# PRINT CV AUC\n",
    "auc = roc_auc_score(train['target'],oof)\n",
    "print('Pseudo Labeled QDA scores CV =',round(auc,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "sub[\"target\"] = preds\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "plt.hist(preds, bins=100)\n",
    "plt.title(\"Final test predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
